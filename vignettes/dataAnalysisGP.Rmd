---
title: Analysis of OCT decays
author: Pascal PERNOT
date: "`r Sys.Date()`"
output:
  bookdown::pdf_document2
citecolor: blue
linkcolor: blue
linestretch: 1.1
fontsize: 12pt
bibliography: /home/pernot/Bureau/ComputChemUnc/biblio.bib
csl: journal-of-signal-processing-systems.csl
---

```{r setup, echo = FALSE, include=FALSE, message=FALSE}
libs =c('parallel','rstan','inlmisc','FitOCTLib')

for (lib in libs ) {
  if(!require(lib,character.only = TRUE))
    install.packages(lib,dependencies=TRUE)
  library(lib,character.only = TRUE)
}

# Options ####
options(mc.cores = parallel::detectCores(), width = 90)
rstan::rstan_options(auto_write = TRUE)
set.seed(1234) # Initialise la graine du RNG

# Graphical parameters ####
gPars = list(
  cols    = inlmisc::GetColors(8),
  col_tr  = inlmisc::GetColors(8,alpha=0.1), # Light, for spaghetti curves
  col_tr2 = inlmisc::GetColors(8,alpha=0.4), # Darker, for legends...
  pty     = 's',
  mar     = c(3,3,1.6,.2),
  mgp     = c(2,.75,0),
  tcl     = -0.5,
  lwd     = 1,
  cex     = 1,
  cex.leg = 0.8,
  xlabel  = 'stromal depth (Âµm)',
  plot_title = '',
  graphTable = FALSE
)

# Control parameters ####

### Default values / Set values here
ctrlPars = list(
  depthSel    = NULL, # Otherwise c(xmin,xmax)
  dataType    = 2,    # Intensity
  subSample   = 1,
  smooth_df   = 15,
  method      = 'sample',
  nb_warmup   = 1000,
  nb_sample   = 1000,
  modRange    = 0.5,
  ru_theta    = 0.05,
  lambda_rate = 0.1,
  gridType    = 'internal',
  Nn          = 10,
  rho_scale   = 0.,
  priPost     = TRUE, # Compare prior and posterior pdf ?
  priorType   = 'abc'
)

# Expose parameters
for (n in names(ctrlPars))
  assign(n,rlist::list.extract(ctrlPars,n))

```



# Introduction

Analysis of  OCT signals by a mono-exponential decay reveals two
features which condition the proposed data analysis method:
an heterogeneous random noise (Poisson-like; see Fig. \@ref(fig:plotNoise1)),
and medium-scale oscillations around the exponential decay 
(model inadequacy; see Fig. \@ref(fig:plotMono1)). 
To be able to partition unambiguously the model residuals 
between these two components, we proceed in two steps:

1. estimation and modeling of the random noise component, to be injected in 

2. the estimation of the parameters of the decay model:
    a. test of a simple monoexponential model
    b. if the latter fails, use of a modulated decay model


```{r getData1, echo = FALSE, cache = TRUE}
dataDir = c("DataWl","Data1","DataSynth")[2]
dataSet = (list.dirs(path=paste0('../',dataDir),full.names = FALSE)[-1])[1]

D = read.csv(paste0('../',dataDir,'/',dataSet,'/Courbe.csv'))
C = FitOCTLib::selX(D[,1],D[,2],depthSel,subSample)
x = C$x; y = C$y

### Estimate data uncertainty
fits = FitOCTLib::estimateNoise(x, y, df = smooth_df)
uy   = fits$uy      # Used by next stages
ySpl = fits$ySmooth # Used by plotMonoExp
```

```{r plotNoise1, echo = FALSE, fig.cap='Splines smoothing and noise estimation'}
gPars$plot_title = 'Noise estimation'
FitOCTLib::plotNoise(x, y, uy, ySpl, gPars, dataType)
gPars$plot_title = ''
```

```{r fitMono1, include =FALSE}
fitm   = FitOCTLib::fitMonoExp(x, y, uy, dataType = dataType)
theta0    = fitm$best.theta   # Used by next stage
cor.theta = fitm$cor.theta
br = FitOCTLib::printBr(fitm$fit)
```


```{r plotMono1, echo = FALSE, fig.cap='Mono-exponential fit and residuals.'}
fit     = fitm$fit
resid   = fit$par$resid
mod     = fit$par$m
gPars$plot_title = 'Mono-exponential fit'
FitOCTLib::plotMonoExp(x, y, uy, ySpl, mod, resid,
                       gPars, dataType, br)
gPars$plot_title = ''
```


# Methods

Considering a set of $N$ measured data points $\pmb D=\{z_i,y_i \}_{i=1}^N$,
one considers a measurement model with heterogeneous additive noise
\begin{equation}  
  y_i = f(z_i) + \epsilon_i 
(\#eq:1)
\end{equation}
where $f(.)$ is a model function to be defined, and
\begin{equation}  
  \epsilon_i \sim Norm(0,\sigma_i) 
(\#eq:2)
\end{equation}
represents an heterogeneous measurement noise with a normal distribution
of standard deviation $\sigma_i$.

## Estimation and modeling of the random noise

A cubic smoothing spline function is used to estimate the random 
part of the signal. 
The residuals $\pmb R=\{R_i\}_{i=1}^N$ of the smoothing function 
are assigned to random noise $\epsilon$.

Considering that the OCT decays result from photon counting experiments,
one can expect that the noise obbeys a Poisson law. 
In consequence, the standard deviation of the noise is modeled by an 
exponential decay
\begin{equation} 
  \sigma_i = a_1 * \exp\left( -\frac{2*z_i}{a_2} \right) 
(\#eq:3)
\end{equation}
This shape enables also to account for cases of _in vivo_ measurements
with nearly uniform noise, by letting $a_2 >> \max(\pmb z)$. 

The parameters are obtained by Bayesian inference [@Gelman2013] 
with likelihood
\begin{equation} 
  \pmb R |a_1, a_2 \sim \prod_{i=1}^N {\rm N}(0,\sigma_i)
(\#eq:likEN)
\end{equation}
and uniform priors for $a_1$ and $a_2$ in the range $]0,a_{max}]$, 
the upper value being chosen to accommodate a quasi-uniform noise model. 
The point estimates of the parameters are used to define the 
measurement uncertainty
\begin{equation} 
  u_{yi} = \hat{a_1} * \exp\left( -\frac{2*z_i}{\hat{a_2}} \right) 
(\#eq:4)
\end{equation}
to be used in the next steps, for which one has now a data set 
augmented with measurement uncertainties $\pmb u_y$, _i.e._ 
$\pmb D= \{ z_i, y_i, u_{yi} \}_{i=1}^N$.

## Calibration of a decay model

### Mono-exponential decay

The mono-exponential decay curve with parameters 
$\pmb \vartheta = \{ a,b,l_0 \}$
\begin{equation} 
  f( z; \pmb \vartheta) = a + b * \exp\left( -\frac{2*z}{l_0} \right)
(\#eq:modExp)
\end{equation}  
is fitted to the data by maximization of the posterior pdf (MAP).
The likelihood is
\begin{equation}
  \pmb y| \pmb \vartheta \sim 
      \prod_{i=1}^N {\rm N}(f(z_i; \pmb \vartheta ),u_{yi})
(\#eq:likExp)
\end{equation}
The parameters have uniform priors on $[0,\infty[$.

#### Validation

One defines the a weighted chi-square function as
\begin{equation}
  \chi_w^2(\pmb y; \pmb z, \pmb u_y, \pmb \vartheta) = 
    \sum_{i=1}^N 
      \frac{[y_i - f(z_i; \pmb \vartheta )]^2}
           {u_{yi}^2}
(\#eq:wChi2)
\end{equation}
The value of the reduced chi-square $\chi_r^2 = \chi_w^2/(N-3)$ should be 
close to 1 ($\chi_r^2 \in IQ_{95}$), based on the quantiles of the reduced
chi-square distribution with $N-3$ degrees of freedom. 
Moreover, the residuals should not present serial correlation. 
If these conditions are not met, one has to use the more elaborate 
model, described below.


### Modulated decay model

The mono-exponential decay model is improved with a $z$-dependent 
optical depth $l(z; l_0, \pmb \kappa)$
\begin{equation} 
  f( z; \pmb \vartheta, \pmb \kappa) = a + b * 
         \exp\left( -\frac{2*z}{l(z; l_0,\pmb \kappa)} \right)
(\#eq:5)
\end{equation}
where the shape of the optical depth is defined as
\begin{equation} 
  l(z; l_0,\pmb \kappa) = l_0*(1+ \delta l(z; \pmb \kappa))
(\#eq:6)
\end{equation}
$\delta l(.)$, _the modulation function_, is a Gaussian Process (GP) 
of mean 0, conditioned on $M$ control values 
$\pmb \kappa= \{\kappa_i\}_{i=1}^M$
at predefined locations 
$\hat{\pmb z} = \{\hat z_i\}_{i=1}^M$.
The mean value of the GP is used here as an interpolator between 
the control points, and we choose a Gaussian kernel for its 
smoothness properties
\begin{equation} 
C(z, z') = \alpha^2 * \exp\left( -\frac{(z-z')^2}{\rho^2} \right)
(\#eq:7)
\end{equation}
The $\alpha$ and $\rho$ parameters of the GP are fixed *a priori*.

Considering the set of $M$ control values $\pmb \kappa$ for the OD 
modulation at locations $\hat{\pmb z}$, $\delta l$ can be obtained 
at any depth as the mean value of the GP:
\begin{equation} 
  \delta l(z; \pmb \kappa) = 
     {\pmb \Omega}^T*{\pmb K}^{-1}*{\pmb \kappa}
(\#eq:8)
\end{equation}
where ${\pmb K}$ is a $M\times M$ covariance matrix with elements 
$K_{ij} = C(\hat z_i, \hat z_j )$ and ${\pmb \Omega}$ is a $M$-vector 
with elements $\Omega_i = C(\hat z_i, z )$.

The control points positions, $\hat{\pmb z}$, are chosen *a priori* 
on a regular grid spanning the experimental depth range. 
As one does not expect short scale modulations, a small number of 
points is used, typically $M\simeq 10$. 
Similarly, for the smoothness of the interpolation, one picks 
the correlation length of the kernel *a priori*, at a value large 
enough to avoid undue oscillations between the control points and 
small enough to avoid excessive rigidity of the model. 
In the present configuration, a good compromise has been found 
to be $\rho = 1/M^{th}$ of the total depth range.
In the same spirit, the variance parameter of the GP is taken as a small
fraction of the standard deviation of the control values 
$\alpha = 0.1 * sd(\pmb \kappa)$. 
This choice of $\alpha$ and $\rho$ has been found to provide a well
behaved interpolator for test simulated signals. 
Besides, small changes around these values do not affect 
significantly the mean prediction of the GP.

#### Prior pdfs

```{r priGP1, include=FALSE, cache=TRUE, dependson='getData1'}
# Prior on exponential params
priExp = FitOCTLib::estimateExpPrior(
  x, uy, dataType, priorType,
  out = fitm, ru_theta = ru_theta,
  eps = 1e-3
)

# Posterior Distribution
priGP = FitOCTLib::fitExpGP(
  x, y, uy,
  dataType      = dataType,
  Nn            = Nn,
  gridType      = gridType,
  method        = method,
  theta0        = priExp$theta0,
  Sigma0        = priExp$Sigma0,
  lambda_rate   = lambda_rate,
  rho_scale     = ifelse(rho_scale==0, 1./Nn, rho_scale),
  nb_warmup     = nb_warmup,
  nb_iter       = nb_warmup + nb_sample,
  prior_PD      = 1,
  open_progress = FALSE
)
```

$\pmb\kappa$. The definition of the modulation function is a source
of indetermination between $l_0$ and $\pmb \kappa$; 
for instance, setting all values of $\pmb \kappa$ to 1 would be 
exactly compensated by halving $l_0$.
One therefore constrains $\pmb \kappa$ to be close to zero
with a Bayesian Lasso-type prior [@Park2008], in a version 
based on a hierarchical prior adapted from Ref.[@Mallick2014]:
\begin{equation}
  \begin{split}
    \kappa_i | u_i & \sim Normal(0, s_i); i=1,M \\
    s_i | \lambda & \sim  Gamma(2, \lambda) ; i=1,M\\
    \lambda & \sim Gamma(2, \lambda_r)
  \end{split}
(\#eq:9)
\end{equation}
where $\lambda_r$ is chosen _a priori_; it defines the scale of 
expected deviations from zero of $\pmb\kappa$ 
(typically $\lambda_r=0.1$). 
An example is shown in Fig. \@ref(fig:plotPriKappa).

```{r plotPriKappa, echo = FALSE, warning = FALSE, fig.cap='Log-prior pdf of a $\\kappa$ parameter.'}
for (n in names(gPars))
  assign(n,rlist::list.extract(gPars,n))
fit = priGP$fit
kappa = as.vector(rstan::extract(fit,'yGP')[[1]]) # Merge all for better stats
par(mfrow=c(1,2), pty=pty, mar=mar, mgp=mgp, tcl=tcl, lwd=lwd, cex=cex)
plot(density(kappa), type='h', log='y', 
     xlim = c(-1,1), xlab= expression(kappa[i]), xaxs='i',
     ylim=c(0.01,10), ylab='Log-density',
     main = '', 
     col  = cols[4])
```


$\pmb\vartheta$. The prior on $\pmb \vartheta$ is a multivariate 
normal distribution
$\pi(\pmb\vartheta) = N(\hat{\pmb \vartheta}_1,\pmb \Sigma_\vartheta)$
centered on the best estimate from the mono-exponential fit, 
$\hat{\pmb \vartheta}_1$, with a covariance matrix 
$\pmb\Sigma_\vartheta$. 
Because the present model is used when the mono-exponential decay
is inadequate, one cannot rely directly on the covariance matrix
extracted from its calibration, $\pmb\Sigma_{\vartheta_1}$.
Instead, a covariance matrix is estimated to cover the range
of variations of the mono-exponential residuals [@Pernot2017b], 
following two approaches:

1. the covariance matrix is built from the correlation matrix
   $\pmb C_{\vartheta_1}$ issued from the monoexponential fit, and a 
   vector of standard deviations specified from relative 
   uncertainties on the parameters:
   \begin{equation}
      \pmb \Sigma_\vartheta = \pmb I(\pmb u_\vartheta) 
                       * \pmb C_{\vartheta_1} 
                       * \pmb I(\pmb u_\vartheta)
   (\#eq:sig1)
   \end{equation}
   where $\pmb I(\pmb u_\vartheta)$ is a diagonal matrix with elements
   $\pmb u_\vartheta = r * \hat{\pmb\vartheta}_1$.
   The uncertainty factor $r$ is typically chosen as a small percentage,
   _e.g._, $r = 0.05$.
   
2. a _diagonal_ covariance matrix 
   $\pmb\Sigma_\vartheta = \pmb I(\pmb u_\vartheta^2)$
   is built by a moments-matching procedure.
   The standard deviations $\pmb u_\vartheta$ are optimized to 
   match two criteria:  
    a. $S_1$, the 2-sigma prediction uncertainty of the mono-exponential
       model has to match $Q_{95}$, the $95^{th}$ quantile of the absolute 
       errors of the mono-exponential model (all statistics are weighted 
       by $\pmb u_y$) [@Pernot2018];   
    b. the standard deviation of the prediction uncertainty has to 
       be as small as possible.   
    The first criterion ensures that the mean prediction uncertainty of
    the mono-exponential model is in agreement with the amplitude of
    the model's residuals [@Pernot2017b]. 
    This criterion can typically be matched by 
    an infinity of solutions, and the second one selects those parameters
    which provides the 'flatest' prediction band. 
    The optimization is done by sampling the posterior pdf of the
    parameters  $\pmb u_\vartheta$ with uniform priors on $[0,\infty[$,
    and a likelihood function
    \begin{equation}
      \left\{Q_{95} ,0\right\} | \pmb u_\vartheta \sim
         {\rm N_2}(\left\{S_1(u_\vartheta) ,S_2(u_\vartheta)\right\},
                   \varepsilon)
    (\#eq:likMM)
    \end{equation}
    where $S_1 = 1.96*\sqrt{<\pmb u_p^2/\pmb u_y^2>}$, $\pmb u_p$ is the
    prediction uncertainty of the mono-exponential model estimated 
    by linear uncertainty propagation [@GUM], 
    $Q_{95}$ is the the $95^{th}$ quantile of the absolute weighted 
    residuals
    $|\left\{\pmb y - f(\pmb z;\pmb \vartheta)\right\} / \pmb u_y|$,
    $S_2 = {\rm sd}(\pmb u_p / \pmb u_y)$
    and $\varepsilon$ is a predefined precision factor ($\varepsilon=10^{-3}$).
    
    A sample generated with this moments-matching prior for an _in vivo_ 
    signal is shown in Fig. \@ref(fig:plotPriGP)(left).

```{r priGP, echo = FALSE, warning = FALSE, cache = TRUE, fig.cap='Samples from prior pdf for an _in vivo_ signal.'}
dataDir = c("DataWl","Data1","DataSynth")[2]
dataSet = (list.dirs(path=paste0('../',dataDir),full.names = FALSE)[-1])[4]
D = read.csv(paste0('../',dataDir,'/',dataSet,'/Courbe.csv'))
C = FitOCTLib::selX(D[,1],D[,2],depthSel,subSample)
x = C$x; y = C$y
fits = FitOCTLib::estimateNoise(x, y, df = smooth_df)
uy   = fits$uy      # Used by next stages
fitm   = FitOCTLib::fitMonoExp(x, y, uy, dataType = dataType)
theta0    = fitm$best.theta   # Used by next stage
cor.theta = fitm$cor.theta
# Prior on exponential params
priExp = FitOCTLib::estimateExpPrior(
  x, uy, dataType, priorType,
  out = fitm, ru_theta = ru_theta,
  eps = 1e-3
)
# Posterior Distribution
priGP = FitOCTLib::fitExpGP(
  x, y, uy,
  dataType      = dataType,
  Nn            = Nn,
  gridType      = gridType,
  method        = method,
  theta0        = priExp$theta0,
  Sigma0        = priExp$Sigma0,
  lambda_rate   = lambda_rate,
  rho_scale     = ifelse(rho_scale==0, 1./Nn, rho_scale),
  nb_warmup     = nb_warmup,
  nb_iter       = nb_warmup + nb_sample,
  prior_PD      = 1,
  open_progress = FALSE
)
```
```{r plotPriGP, echo = FALSE, warning = FALSE, fig.cap='Samples from prior pdf for an _in vivo_ signal.'}
gPars$plot_title = 'Prior exponential'
FitOCTLib::plotExpGP(
  x, y, uy, ySpl, out=priGP, modScale=modRange*2, gPars=gPars,
  dataType = dataType, br = br
)
gPars$plot_title = ' '
```

$\sigma$. To compensate for defaults in the estimation of the noise, 
a parameter $\sigma$ is introduced as a multiplicative factor
of $\pmb u(y)$. The prior on $\sigma$ is a normal distribution, 
centered on 1, with standard deviation 0.1.

The parameters to be sampled are therefore $\pmb\vartheta$, $\pmb\kappa$,
$\lambda_r$ and $\sigma$.

#### Likelihood function

The likelihood function is the product of univariate normal distributions
\begin{equation}
  \pmb y| \pmb \vartheta, \pmb \kappa , \sigma,  \sim 
      \prod_{i=1}^N {\rm N}(f(z_i; \pmb \vartheta, \pmb \kappa ),
                            \sigma*u_{yi})
(\#eq:likMod)
\end{equation}


#### Validation

The quality of the fit can be estimated by inspection of
the residuals which should not present serial correlations 
and should conform with the random experimental noise. 

The value of the reduced chi-square $\chi_r^2 = \chi_w^2/(N-\nu)$, 
where $\nu$ is the number of effective free parameters, should be 
close to 1. One has $\nu = 5 + \hat M$, where $0\le \hat M\le M$ 
is the number of control values significantly different from zero, 
_i.e._ those for which $0 \notin IQ_{90}(\kappa_i)$.

Posterior predictive samples are also generated and plotted 
with the reference data to confirm the quality of the fit.

# Implementation

The core functions are in the package [FitOCTLib](https://github.com/ppernot/FitOCTlib).

__Basic algorithm__

0. Read signal `(x, y)` and apply eventual thinning and 
   subsetting with function `selX()`

1. Noise estimation: `en <- estimateNoise(x, y)` which returns
   a list containing `uy`

2. Mono-exponential fit: `fit1 <- fitMonoExp(x, y, en$uy)`.
   Validity is checked by function `br <- printBr(fit1)`.
   If `is.null(br$alert)`, the model is OK, on can stop.

3. Modulated exponential fit: `fit2 <- fitExpGP(x, y, en$uy)`.
   If the fit is not valid (`!is.null(printBr(fit2)$alert)`)),
   one might increase the number of control points, _e.g._
   `fit2 <- fitExpGP(x, y, en$uy, Nn = 15)`.


## Smoothing 

Estimation of the random errors is done with the `smooth.spline` from 
`R` [@RCoreTeam]; A satisfying degree of smoothing for all examples
considered here was obtained by setting the smoothing `df` parameter 
to 15.

## Bayesian inference 

The Bayesian models are implemented in `stan` [@Gelman2015], using the
`rstan` interface package [@Rstan] for `R` [@RCoreTeam]. 
`Stan` is a very flexible and efficient probabilistic programming 
language to implement Bayesian statistical models. 
The No-U-Turn sampler [@Hoffman2014] was used for this study.

The main outputs of the stan codes are samples of the posterior pdf of
the parameters, from which statistics and plots can be generated in R.
Convergence of the sampling is assessed by examining the traces of
parameters samples and the 'split Rhat' statistics provided by rstan. In
the present application, the Markov chains converge rapidly, and all
models are run with four parallel Markov Chains of 1500 iterations each,
1000 of which are used as warm-up for the No-U-Turn sampler and
dispatched. The convergence criteria and parameters statistics are
therefore estimated on a sample of 2000 points.


# References

