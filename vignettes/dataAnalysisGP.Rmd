---
title: Analysis of OCT decays
author: Pascal PERNOT
date: "`r Sys.Date()`"
output:
  bookdown::pdf_document2
citecolor: blue
linkcolor: blue
linestretch: 1.1
fontsize: 12pt
bibliography: /home/pernot/Bureau/ComputChemUnc/biblio.bib
csl: journal-of-signal-processing-systems.csl
---

```{r setup, echo = FALSE, include=FALSE, message=FALSE}
libs =c('parallel','rstan','inlmisc','FitOCTLib')

for (lib in libs ) {
  if(!require(lib,character.only = TRUE))
    install.packages(lib,dependencies=TRUE)
  library(lib,character.only = TRUE)
}

# Options ####
options(mc.cores = parallel::detectCores(), width = 90)
rstan::rstan_options(auto_write = TRUE)
set.seed(1234) # Initialise la graine du RNG

# Graphical parameters ####
gPars = list(
  cols    = inlmisc::GetColors(8),
  col_tr  = inlmisc::GetColors(8,alpha=0.1), # Light, for spaghetti curves
  col_tr2 = inlmisc::GetColors(8,alpha=0.4), # Darker, for legends...
  pty     = 's',
  mar     = c(3,3,1.6,.2),
  mgp     = c(2,.75,0),
  tcl     = -0.5,
  lwd     = 1,
  cex     = 1,
  cex.leg = 0.8,
  xlabel  = 'stromal depth (Âµm)',
  plot_title = '',
  graphTable = FALSE
)

# Control parameters ####

### Default values / Set values here
ctrlPars = list(
  depthSel    = NULL, # Otherwise c(xmin,xmax)
  dataType    = 2,    # Intensity
  subSample   = 1,
  smooth_df   = 15,
  method      = 'sample',
  nb_warmup   = 1000,
  nb_sample   = 1000,
  modRange    = 0.5,
  ru_theta    = 0.05,
  lambda_rate = 0.1,
  gridType    = 'internal',
  Nn          = 10,
  rho_scale   = 0.,
  priPost     = TRUE, # Compare prior and posterior pdf ?
  priorType   = 'abc'
)

# Expose parameters
for (n in names(ctrlPars))
  assign(n,rlist::list.extract(ctrlPars,n))

```



# Introduction

Analysis of OCT signals by a mono-exponential decay typically 
reveals two features which condition the data analysis method 
proposed here:

* an heterogeneous, Poisson-like, random noise(Fig. \@ref(fig:plotNoise1))
* medium-scale oscillations around the exponential decay, revealing
model inadequacy (Fig. \@ref(fig:plotMono1)).  

To be able to partition unambiguously the model residuals 
between these two components, we proceed in two steps:

1. estimation and modeling of the random noise component 
2. estimation of the parameters of the decay model. 
Knowing the noise enables to (in-)validate a mono-exponential
decay model
    a. test of a simple mono-exponential decay model
    b. if invalid, use a modulated decay model

The latter model fits the deviations of the signal from
an ideal mono-exponential.

The next sections present the statistical aspects of this 
procedure in a Bayesian framework. Please see Refs. 
[@Gregory2005;@Sivia06;@Gelman2013;@McElreath2015]
for an introduction to Bayesian data analysis.

```{r getData1, echo = FALSE, cache = TRUE}
dataDir = c("DataWl","Data1","DataSynth")[2]
dataSet = (list.dirs(path=paste0('../',dataDir),full.names = FALSE)[-1])[1]

D = read.csv(paste0('../',dataDir,'/',dataSet,'/Courbe.csv'))
C = FitOCTLib::selX(D[,1],D[,2],depthSel,subSample)
x = C$x; y = C$y

### Estimate data uncertainty
fits = FitOCTLib::estimateNoise(x, y, df = smooth_df)
uy   = fits$uy      # Used by next stages
ySpl = fits$ySmooth # Used by plotMonoExp
```

```{r plotNoise1, echo = FALSE, fig.cap='Splines smoothing and noise estimation'}
gPars$plot_title = 'Noise estimation'
FitOCTLib::plotNoise(x, y, uy, ySpl, gPars, dataType)
gPars$plot_title = ''
```

```{r fitMono1, include =FALSE}
fitm   = FitOCTLib::fitMonoExp(x, y, uy, dataType = dataType)
theta0    = fitm$best.theta   # Used by next stage
cor.theta = fitm$cor.theta
br = FitOCTLib::printBr(fitm$fit)
```


```{r plotMono1, echo = FALSE, fig.cap='Mono-exponential fit and residuals.'}
fit     = fitm$fit
resid   = fit$par$resid
mod     = fit$par$m
gPars$plot_title = 'Mono-exponential fit'
FitOCTLib::plotMonoExp(x, y, uy, ySpl, mod, resid,
                       gPars, dataType, br)
gPars$plot_title = ''
```


# Methods

Considering a set of $N$ measured data points $\pmb D=\{z_i,y_i \}_{i=1}^N$,
one considers a measurement model with heterogeneous additive noise
\begin{equation}  
  y_i = f(z_i) + \epsilon_i 
(\#eq:1)
\end{equation}
where $f(.)$ is a model function to be defined, and
\begin{equation}  
  \epsilon_i \sim Norm(0,\sigma_i) 
(\#eq:2)
\end{equation}
represents a measurement noise with a normal distribution of mean zero 
and standard deviation $\sigma_i$.

## Estimation and modeling of the random noise

A cubic smoothing spline function is used to estimate the random 
part of the signal. 
The residuals $\pmb R=\{R_i\}_{i=1}^N$ of the smoothing function 
are assigned to random noise $\epsilon$.

Considering that the OCT decays result from photon counting experiments,
one can expect that the noise obbeys a Poisson law. 
In consequence, the standard deviation of the noise is modeled by an 
exponential decay
\begin{equation} 
  \sigma_i = a_1 * \exp\left( -\frac{2*z_i}{a_2} \right) 
(\#eq:3)
\end{equation}
This shape enables also to account for cases of _in vivo_ measurements
with nearly uniform noise, by letting $a_2 >> \max(\pmb z)$. 

The parameters are obtained by Bayesian inference [@Gelman2013] 
with likelihood
\begin{equation} 
  \pmb R |a_1, a_2 \sim \prod_{i=1}^N {\rm N}(0,\sigma_i)
(\#eq:likEN)
\end{equation}
and uniform priors for $a_1$ and $a_2$ in the range $]0,a_{max}]$, 
the upper value being chosen to accommodate a quasi-uniform noise model. 
The point estimates of the parameters are used to define the 
measurement uncertainty
\begin{equation} 
  u_{yi} = \hat{a_1} * \exp\left( -\frac{2*z_i}{\hat{a_2}} \right) 
(\#eq:4)
\end{equation}
to be used in the next steps, for which one has now a data set 
augmented with measurement uncertainties $\pmb u_y$, _i.e._ 
$\pmb D= \{ z_i, y_i, u_{yi} \}_{i=1}^N$.

## Calibration of a decay model

### Mono-exponential decay

The mono-exponential decay curve with parameters 
$\pmb \vartheta = \{ a,b,l_0 \}$
\begin{equation} 
  f( z; \pmb \vartheta) = a + b * \exp\left( -\frac{2*z}{l_0} \right)
(\#eq:modExp)
\end{equation}  
is fitted to the data by maximization of the posterior pdf (MAP).
In absence of correlation, the likelihood is a product of univariate 
normal distributions 
\begin{equation}
  \pmb y| \pmb \vartheta \sim 
      \prod_{i=1}^N {\rm N}(f(z_i; \pmb \vartheta ),u_{yi})
(\#eq:likExp)
\end{equation}
The parameters have uniform priors on $[0,\infty[$.

#### Validation

One defines the a weighted chi-square function as
\begin{equation}
  \chi_w^2(\pmb y; \pmb z, \pmb u_y, \pmb \vartheta) = 
    \sum_{i=1}^N 
      \frac{[y_i - f(z_i; \pmb \vartheta )]^2}
           {u_{yi}^2}
(\#eq:wChi2)
\end{equation}
The value of the Birge's ratio $R_B$ or reduced chi-square 
$\chi_r^2 = \chi_w^2/(N-3)$ should be close to 1 ($\chi_r^2 \in IQ_{95}$), 
based on the quantiles of the reduced chi-square distribution 
with $N-3$ degrees of freedom. 

Moreover, the residuals should not present serial correlation. 
If both conditions are not met, the mono-exponential decay is
inadequate, and one has to use the more elaborate model 
described next.

### Modulated decay model

The mono-exponential decay model is improved with a $z$-dependent 
optical depth $l(z; l_0, \pmb \kappa)$
\begin{equation} 
  f( z; \pmb \vartheta, \pmb \kappa) = a + b * 
         \exp\left( -\frac{2*z}{l(z; l_0,\pmb \kappa)} \right)
(\#eq:5)
\end{equation}
where the shape of the optical depth is defined as
\begin{equation} 
  l(z; l_0,\pmb \kappa) = l_0*(1+ \delta l(z; \pmb \kappa))
(\#eq:6)
\end{equation}
$\delta l(.)$, _the modulation function_, is a Gaussian Process (GP) 
of mean 0, conditioned on $M$ control values 
$\pmb \kappa= \{\kappa_i\}_{i=1}^M$
at predefined locations 
$\hat{\pmb z} = \{\hat z_i\}_{i=1}^M$.
The mean value of the GP is used here as an interpolator between 
the control points, and we choose a Gaussian kernel for its 
smoothness properties
\begin{equation} 
C(z, z') = \alpha^2 * \exp\left( -\frac{(z-z')^2}{\rho^2} \right)
(\#eq:7)
\end{equation}

Considering the set of $M$ control values $\pmb \kappa$ for the OD 
modulation at locations $\hat{\pmb z}$, $\delta l$ can be obtained 
at any depth as the mean value of the GP:
\begin{equation} 
  \delta l(z; \pmb \kappa) = 
     {\pmb \Omega}^T*{\pmb K}^{-1}*{\pmb \kappa}
(\#eq:8)
\end{equation}
where ${\pmb K}$ is a $M\times M$ covariance matrix with elements 
$K_{ij} = C(\hat z_i, \hat z_j )$ and ${\pmb \Omega}$ is a $M$-vector 
with elements $\Omega_i = C(\hat z_i, z )$.

The control points positions, $\hat{\pmb z}$, are chosen *a priori* 
on a regular grid spanning the experimental depth range. 
As one does not expect short scale modulations, a small number of 
points is used, typically $M\simeq 10$. 
Similarly, for the smoothness of the interpolation, one picks 
the correlation length of the kernel *a priori*, at a value large 
enough to avoid undue oscillations between the control points and 
small enough to avoid excessive rigidity of the model. 
In the present configuration, a good compromise has been found 
to be $\rho = 1/M^{th}$ of the total depth range.
In the same spirit, the variance parameter of the GP is taken as a small
fraction of the standard deviation of the control values 
$\alpha = 0.1 * sd(\pmb \kappa)$. 
This choice of $\alpha$ and $\rho$ has been found to provide a well
behaved interpolator for test simulated signals. 
Besides, small changes around these values do not affect 
significantly the mean prediction of the GP.

#### Prior pdfs

```{r priGP1, include=FALSE, cache=TRUE, dependson='getData1'}
# Prior on exponential params
priExp = FitOCTLib::estimateExpPrior(
  x, uy, dataType, priorType,
  out = fitm, ru_theta = ru_theta,
  eps = 1e-3
)

# Posterior Distribution
priGP = FitOCTLib::fitExpGP(
  x, y, uy,
  dataType      = dataType,
  Nn            = Nn,
  gridType      = gridType,
  method        = method,
  theta0        = priExp$theta0,
  Sigma0        = priExp$Sigma0,
  lambda_rate   = lambda_rate,
  rho_scale     = ifelse(rho_scale==0, 1./Nn, rho_scale),
  nb_warmup     = nb_warmup,
  nb_iter       = nb_warmup + nb_sample,
  prior_PD      = 1,
  open_progress = FALSE
)
```

$\pmb\kappa$. The definition of the modulation function is a source
of indetermination between $l_0$ and $\pmb\kappa$; 
for instance, setting all values of $\pmb\kappa$ to 1 would be 
exactly compensated by halving $l_0$.
One therefore constrains $\pmb\kappa$ to be close to zero
using a Bayesian Lasso-type prior [@Park2008], in a version 
based on a hierarchical prior adapted from Ref.[@Mallick2014]:
\begin{equation}
  \begin{split}
    \kappa_i | u_i & \sim Normal(0, s_i); i=1,M \\
    s_i | \lambda & \sim  Gamma(2, \lambda) ; i=1,M\\
    \lambda & \sim Gamma(2, \lambda_r)
  \end{split}
(\#eq:9)
\end{equation}
where $\lambda_r$ is chosen _a priori_; it defines the scale of 
expected deviations from zero of $\pmb\kappa$ (typically $\lambda_r=0.1$). 
An example is shown in Fig. \@ref(fig:plotPriKappa).

```{r plotPriKappa, echo = FALSE, warning = FALSE, fig.cap='Log-prior pdf of a $\\kappa$ parameter.'}
for (n in names(gPars))
  assign(n,rlist::list.extract(gPars,n))
fit = priGP$fit
kappa = as.vector(rstan::extract(fit,'yGP')[[1]]) # Merge all for better stats
par(mfrow=c(1,2), pty=pty, mar=mar, mgp=mgp, tcl=tcl, lwd=lwd, cex=cex)
plot(density(kappa), type='h', log='y', 
     xlim = c(-1,1), xlab= expression(kappa[i]), xaxs='i',
     ylim=c(0.01,10), ylab='Log-density',
     main = '', 
     col  = cols[4])
```


$\pmb\vartheta$. The prior on $\pmb \vartheta$ is a multivariate 
normal distribution
$\pi(\pmb\vartheta) = N(\hat{\pmb \vartheta}_1,\pmb \Sigma_\vartheta)$
centered on the best estimate from the mono-exponential fit, 
$\hat{\pmb \vartheta}_1$, with a covariance matrix $\pmb\Sigma_\vartheta$. 
Because the present model is used when the mono-exponential decay
is inadequate, one cannot rely directly on the covariance matrix
extracted from its calibration, $\pmb\Sigma_{\vartheta_1}$.
Instead, a covariance matrix is designed to enable  decays covering
the range of variations of the mono-exponential residuals [@Pernot2017b]. 
Two approaches have been implemented:

1. the covariance matrix is built from the correlation matrix
   $\pmb C_{\vartheta_1}$ issued from the monoexponential fit, 
   and a vector of standard deviations specified by a relative 
   uncertainty on the parameters:
   \begin{equation}
      \pmb \Sigma_\vartheta = \pmb I(\pmb u_\vartheta) 
                       * \pmb C_{\vartheta_1} 
                       * \pmb I(\pmb u_\vartheta)
   (\#eq:sig1)
   \end{equation}
   where $\pmb I(\pmb u_\vartheta)$ is a diagonal matrix with elements
   $\pmb u_\vartheta = r * \hat{\pmb\vartheta}_1$.
   The uncertainty factor $r$ is typically chosen as a small percentage,
   _e.g._, $r = 0.05$.
   
2.  a _diagonal_ covariance matrix 
    $\pmb\Sigma_\vartheta = \pmb I(\pmb u_\vartheta^2)$
    is built by a moments-matching procedure. 
    The standard deviations $\pmb u_\vartheta$ are optimized to 
    match two criteria^[Premiminary tests have shown that the correlation 
    parameters are not well identified by this type of approach, and 
    that they do not enable a notable improvement of the fit. It is 
    therefore much simpler to deal with a diagonal matrix]:  
    a. $S_1$, the 2-sigma prediction uncertainty of the mono-exponential
       model has to match $Q_{95}$, the $95^{th}$ quantile of the absolute 
       errors of the mono-exponential model (all statistics are weighted 
       by $\pmb u_y$) [@Pernot2018];   
    b. the standard deviation of the prediction uncertainty has to 
       be as small as possible.
       
    The first criterion ensures that the mean prediction uncertainty of
    the mono-exponential model is in agreement with the amplitude of
    the model's residuals [@Pernot2017b]. 
    This criterion can typically be matched by an infinity of solutions, 
    and the second one selects those parameters which provides the 
    'flatest' prediction band. 
    The optimization is done by sampling the posterior pdf of the
    parameters  $\pmb u_\vartheta$ with uniform priors on $[0,\infty[$,
    and a bivariate normal likelihood function
    \begin{equation}
      \left\{Q_{95} ,0\right\} | \pmb u_\vartheta \sim
         {\rm N_2}(\left\{S_1(u_\vartheta) ,S_2(u_\vartheta)\right\},
                   \varepsilon)
    (\#eq:likMM)
    \end{equation}
    where $S_1 = 1.96*\sqrt{<\pmb u_p^2/\pmb u_y^2>}$, $\pmb u_p$ is the
    prediction uncertainty of the mono-exponential model estimated 
    by linear uncertainty propagation [@GUM], 
    $Q_{95}$ is the the $95^{th}$ quantile of the absolute weighted 
    residuals
    $|\left\{\pmb y - f(\pmb z;\pmb \vartheta)\right\} / \pmb u_y|$,
    $S_2 = {\rm sd}(\pmb u_p / \pmb u_y)$
    and $\varepsilon$ is a predefined precision factor ($\varepsilon=10^{-3}$).
    
    A sample generated with this moments-matching prior for an _in vivo_ 
    signal is shown in Fig. \@ref(fig:plotPriGP)(left).

```{r priGP, echo = FALSE, warning = FALSE, cache = TRUE, fig.cap='Samples from prior pdf for an _in vivo_ signal.'}
dataDir = c("DataWl","Data1","DataSynth")[2]
dataSet = (list.dirs(path=paste0('../',dataDir),full.names = FALSE)[-1])[4]
D = read.csv(paste0('../',dataDir,'/',dataSet,'/Courbe.csv'))
C = FitOCTLib::selX(D[,1],D[,2],depthSel,subSample)
x = C$x; y = C$y
fits = FitOCTLib::estimateNoise(x, y, df = smooth_df)
uy   = fits$uy      # Used by next stages
fitm   = FitOCTLib::fitMonoExp(x, y, uy, dataType = dataType)
theta0    = fitm$best.theta   # Used by next stage
cor.theta = fitm$cor.theta
# Prior on exponential params
priExp = FitOCTLib::estimateExpPrior(
  x, uy, dataType, priorType,
  out = fitm, ru_theta = ru_theta,
  eps = 1e-3
)
# Posterior Distribution
priGP = FitOCTLib::fitExpGP(
  x, y, uy,
  dataType      = dataType,
  Nn            = Nn,
  gridType      = gridType,
  method        = method,
  theta0        = priExp$theta0,
  Sigma0        = priExp$Sigma0,
  lambda_rate   = lambda_rate,
  rho_scale     = ifelse(rho_scale==0, 1./Nn, rho_scale),
  nb_warmup     = nb_warmup,
  nb_iter       = nb_warmup + nb_sample,
  prior_PD      = 1,
  open_progress = FALSE
)
```
```{r plotPriGP, echo = FALSE, warning = FALSE, fig.cap='Samples from prior pdf for an _in vivo_ signal.'}
gPars$plot_title = 'Prior exponential'
FitOCTLib::plotExpGP(
  x, y, uy, ySpl, out=priGP, modScale=modRange*2, gPars=gPars,
  dataType = dataType, br = br
)
gPars$plot_title = ' '
```

$\sigma$. To compensate for defaults in the estimation of the noise, 
a parameter $\sigma$ is introduced as a multiplicative factor
of $\pmb u(y)$. The prior on $\sigma$ is a normal distribution, 
centered on 1, with standard deviation 0.1.

The parameters to be sampled are therefore $\pmb\vartheta$, $\pmb\kappa$,
$\lambda_r$ and $\sigma$.

#### Likelihood function

As for the mono-exponential decay model, the likelihood function 
is the product of univariate normal distributions
\begin{equation}
  \pmb y| \pmb \vartheta, \pmb \kappa , \sigma,  \sim 
      \prod_{i=1}^N {\rm N}(f(z_i; \pmb \vartheta, \pmb \kappa ),
                            \sigma*u_{yi})
(\#eq:likMod)
\end{equation}


#### Validation

The quality of the fit can be estimated by inspection of
the residuals which should not present serial correlations 
and should conform with the random experimental noise. 

The value of the reduced chi-square $\chi_r^2 = \chi_w^2/(N-\nu)$, 
where $\nu$ is the number of effective free parameters, should be 
close to 1. One has $\nu = 5 + \hat M$, where $0\le \hat M\le M$ 
is the number of control values significantly different from zero, 
_i.e._ those for which $0 \notin IQ_{90}(\kappa_i)$.

Posterior predictive samples are also generated and plotted 
with the reference data to confirm the quality of the fit.

# Implementation

The core functions are in the package [FitOCTLib](https://github.com/ppernot/FitOCTlib).

__Basic algorithm__

0. Read signal `(x, y)` and apply eventual thinning and 
   subsetting with function `selX()`

1. Noise estimation: `en <- estimateNoise(x, y)` which returns
   a list containing `uy`

2. Mono-exponential fit: `fit1 <- fitMonoExp(x, y, en$uy)`.
   Validity is checked by function `br <- printBr(fit1)`.
   If `is.null(br$alert)`, the model is OK, on can stop.

3. Modulated exponential fit: `fit2 <- fitExpGP(x, y, en$uy)`.
   If the fit is not valid (`!is.null(printBr(fit2)$alert)`)),
   one might increase the number of control points, _e.g._
   `fit2 <- fitExpGP(x, y, en$uy, Nn = 15)`.


## Smoothing 

Estimation of the random errors is done with the `smooth.spline` from 
`R` [@RCoreTeam]; A satisfying degree of smoothing for all examples
considered here was obtained by setting the smoothing `df` parameter 
to 15.

## Bayesian inference 

The Bayesian models are implemented in `stan` [@Gelman2015], using the
`rstan` interface package [@Rstan] for `R` [@RCoreTeam]. 
`Stan` is a very flexible and efficient probabilistic programming 
language to implement Bayesian statistical models. 
The No-U-Turn sampler [@Hoffman2014] was used for this study.

The main outputs of the stan codes are samples of the posterior pdf of
the parameters, from which statistics and plots can be generated in R.
Convergence of the sampling is assessed by examining the traces of
parameters samples and the 'split Rhat' statistics provided by rstan. In
the present application, the Markov chains converge rapidly, and all
models are run with four parallel Markov Chains of 1500 iterations each,
1000 of which are used as warm-up for the No-U-Turn sampler and
dispatched. The convergence criteria and parameters statistics are
therefore estimated on a sample of 2000 points.


# References

